# -*- coding: utf-8 -*-
"""Submission Pertama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xGPyNVjqPZpN8bDONosj3jy0Nd2O6lVr

# **Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech**
Nama: Bayun Kurniawan

Email: bayunk59@gmail.com

Id Dicoding: Bayun Kurniawan

# **Preparation**

## Gathering Data
"""

# Import

!pip install pandas sqlalchemy
from sqlalchemy import create_engine
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import PowerTransformer
import joblib
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Ambil data

jayaMaju_df = pd.read_csv(
    "https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/employee/employee_data.csv")
jayaMaju_df.head(5)

"""## Data Cleansing"""

jayaMaju_df.info()

# Mencari data yang memiliki missing value

jayaMaju_df.isna().sum()

# Cek missing value

jayaMaju_df[jayaMaju_df.Attrition.isna()]

jayaMaju_df.Attrition.value_counts()

# Menghapus missing value

jayaMaju_df = jayaMaju_df.dropna()

jayaMaju_df.isna().sum()

jayaMaju_df.info()

"""# **Data Understanding**"""

jayaMaju_df.describe(include="all")

# distribusi jumlah `Attriton`

sns.countplot(x='Attrition', data=jayaMaju_df)
plt.title("Distribusi Karyawan Keluar vs Tidak")
plt.show()

print(jayaMaju_df['Attrition'].value_counts(normalize=True))

# Membagi data berdasarkan type

numerical = ["EmployeeId", "Age", "Attrition", "DailyRate", "DistanceFromHome", "Education",
             "EmployeeCount", "EnvironmentSatisfaction", "HourlyRate", "JobInvolvement", "JobLevel",
             "JobSatisfaction", "MonthlyIncome", "MonthlyRate", "NumCompaniesWorked",
             "PercentSalaryHike", "PerformanceRating", "RelationshipSatisfaction", "StandardHours",
             "StockOptionLevel", "TotalWorkingYears", "TrainingTimesLastYear", "WorkLifeBalance",
             "YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsWithCurrManager"]

categorical = ["BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus",
               "Over18", "OverTime"]

"""## Numerical Data

"""

jayaMaju_df[numerical].hist(bins=20, grid=False, figsize=(15, 12))
plt.tight_layout()
plt.show()

# Hubungan data numerik dengan `Attrition`

fig, axes = plt.subplots(nrows=7, ncols=4, figsize=(18, 28))
axes = axes.ravel()

for i, col in enumerate(numerical):
    sns.boxplot(data=jayaMaju_df, x='Attrition', y=col, ax=axes[i])
    axes[i].set_title(f'{col} vs Attrition')

# Kosongkan plot yang tidak terpakai jika jumlah subplot lebih banyak
for j in range(len(numerical), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Nilai korelasi data numerik dengan `Attrition`

plt.figure(figsize=(15, 15))
sns.heatmap(jayaMaju_df[numerical].corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title("Korelasi antar fitur numerik")
plt.show()

"""Berdasarkan hasil korelasi `Attrition` dengan tipe data numerik didapatkan beberapa fitur yang berpengaruh:
1. `Age` -0.17
2. `EnvironmentSatisfaction` -0.13
3. `JobInvolvement` -0.15
4. `JobLevel` -0.17
5. `JobSatisfaction` -0.09
6. `MonthlyIncome` -0.16
7. `StockOptionLevel` -0.16
8. `TotalWorkingYears` -0.18
9. `YearsAtCompany` -0.14
10. `YearsInCurrentRole` -0.16
11. `YearsWithCurrManager` -0.16

1. `DistanceFromHome` +0.08

## Categorical Data
"""

# Hubungan data kategork dengan `Attrition`

fig, axes = plt.subplots(nrows=len(categorical), ncols=1, figsize=(10, 6 * len(categorical)))

if len(categorical) == 1:
    axes = [axes]  # supaya tetap iterable kalau cuma 1 kolom

for i, col in enumerate(categorical):
    sns.countplot(data=jayaMaju_df, x=col, hue='Attrition', ax=axes[i])
    axes[i].set_title(f'{col} vs Attrition')
    axes[i].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

"""# **Data Preparation / Preprocessing**"""

# Buat salinan data

main_df = jayaMaju_df.copy()

# Menghapus beberapa kolom yang tidak berpengaruh

main_df.drop(columns=["EmployeeId", "DailyRate", "Education", "EmployeeCount",
                      "PerformanceRating", "HourlyRate", "MonthlyRate", "StandardHours",
                      "NumCompaniesWorked", "PercentSalaryHike", "PerformanceRating",
                      "RelationshipSatisfaction", "StandardHours", "TrainingTimesLastYear",
                      "WorkLifeBalance"], inplace=True)

# One-hot encoding untuk fitur kategorik
main_df = pd.concat([main_df, pd.get_dummies(main_df['BusinessTravel'], prefix='BusinessTravel')], axis=1)
main_df = pd.concat([main_df, pd.get_dummies(main_df['Department'], prefix='Department')], axis=1)
main_df = pd.concat([main_df, pd.get_dummies(main_df['EducationField'], prefix='EducationField')], axis=1)
main_df = pd.concat([main_df, pd.get_dummies(main_df['Gender'], prefix='Gender')], axis=1)
main_df = pd.concat([main_df, pd.get_dummies(main_df['JobRole'], prefix='JobRole')], axis=1)
main_df = pd.concat([main_df, pd.get_dummies(main_df['MaritalStatus'], prefix='MaritalStatus')], axis=1)
main_df = pd.concat([main_df, pd.get_dummies(main_df['OverTime'], prefix='OverTime')], axis=1)

# Hapus kolom aslinya
main_df.drop(['BusinessTravel', 'Department', 'EducationField', 'Gender',
         'JobRole', 'MaritalStatus', 'OverTime', 'Over18'], axis=1, inplace=True)

# Lihat hasil encoding
main_df.head()

"""## Train-Test-Split"""

X = main_df.drop(["Attrition"],axis =1)
y = main_df["Attrition"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Standarisasi"""

numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()

scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""# **Modelling**

## Logistic Regression
"""

# Inisialisasi model
logreg = LogisticRegression(max_iter=1000)

# Latih model
logreg.fit(X_train, y_train)

# Prediksi di data test
y_pred = logreg.predict(X_test)

# Evaluasi model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

"""## Random Forest"""

# Inisialisasi model
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Latih model
rf.fit(X_train, y_train)

# Prediksi
y_pred_rf = rf.predict(X_test)

# Evaluasi
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

"""## Decision Tree"""

# Inisialisasi model
dtree = DecisionTreeClassifier(random_state=42, max_depth=5)  # boleh atur max_depth agar tidak overfitting

# Latih model
dtree.fit(X_train, y_train)

# Prediksi
y_pred_dt = dtree.predict(X_test)

# Evaluasi
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

"""# **Evaluation**"""

# Inisialisasi model
logreg = LogisticRegression(max_iter=1000)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
dtree = DecisionTreeClassifier(random_state=42, max_depth=5)

# Dictionary untuk menyimpan model dan hasil evaluasi
models = {
    "Logistic Regression": logreg,
    "Random Forest": rf,
    "Decision Tree": dtree
}

# Dictionary untuk menyimpan skor akurasi
accuracies = {}

# Fungsi evaluasi
def evaluate_model(name, model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    accuracies[name] = acc

    print(f"=== {name} ===")
    print("Accuracy:", acc)
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("\n" + "="*50 + "\n")

# Evaluasi semua model
for name, model in models.items():
    evaluate_model(name, model, X_train, y_train, X_test, y_test)

# Cari model dengan akurasi tertinggi
best_model_name = max(accuracies, key=accuracies.get)
best_accuracy = accuracies[best_model_name]

# Rekomendasi
print(f"ðŸ“Œ Rekomendasi Model:")
print(f"Model terbaik berdasarkan akurasi adalah **{best_model_name}** dengan akurasi sebesar **{best_accuracy:.2f}**.")

"""# **Mengirim dataset ke dalam database**"""

URL = "postgresql://postgres.umoicvvdhelmxiytovql:Napoleon007@aws-0-ap-southeast-1.pooler.supabase.com:6543/postgres"

engine = create_engine(URL)
jayaMaju_df.to_sql('AttritionRate', engine)

"""# **requirements**"""

!pip freeze > requirements.txt